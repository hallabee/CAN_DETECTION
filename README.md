# Can Detection AI

## Overview

This project focuses on developing an AI model capable of detecting cans in real-time using advanced computer vision techniques. The core model is built on **YOLOv5** (You Only Look Once), a state-of-the-art object detection framework. By automating can detection, the project aims to address environmental challenges such as waste management and recycling inefficiencies.

The initial experiment (Exp1) uses a custom dataset of cans, with images and annotations provided in the `data/train` folder. This dataset enables the AI model to learn and effectively identify cans under varying conditions.

## How It Works

1. **Dataset**: 
   - The dataset is located in the `data/train` folder. It consists of labeled images of cans captured in diverse environments, ensuring robust detection across real-world scenarios.

2. **Model Architecture**:
   - YOLOv5 is employed for its high speed and accuracy, making it ideal for detecting cans in real-time applications like recycling plants or waste sorting systems.

3. **Training**:
   - The model is trained on labeled images, which include bounding boxes around cans. Through this training, the AI learns to recognize cans in complex scenes.

4. **Inference**:
   - The trained model can detect cans in live video streams or static images. It outputs bounding boxes, class names, and confidence scores, enabling real-time applications.

## Installation

1. Clone the repository:
   ```bash
   git clone <repository-url>
   ```
Install the dependencies:

```bash
pip install -r requirements.txt
```
Download YOLOv5 weights:

The trained weights (best.pt) are located in the runs/train folder or can be generated by training the model using the provided dataset.
Running the Detection
Training: To train the model on the dataset, use the following command:

```bash
python train.py --data data.yaml --cfg models/yolov5s.yaml --weights yolov5s.pt --epochs 100
```
Inference: To run detection on new images or videos using the trained weights, execute:

```bash
python detect.py --source <video_or_image_path> --weights runs/train/best.pt
```
## Results
   In the initial experiment (Exp1), the model achieved:

   Accuracy: 94%
   
   Precision: 89%
   
The results demonstrate that the model can reliably detect cans, even in challenging conditions.

## Future Work
   Expand the dataset to include a wider variety of can types and environments.
   Integrate the AI into recycling lines for real-time sorting and waste management.
   Develop an edge AI system for deployment in low-resource environments.

## License
   This project is licensed under the MIT License - see the LICENSE file for details.
